{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305c0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a99c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_nonlinear = './results_nonlinear_vm1'\n",
    "\n",
    "csv_file_nonlinear = 'nonlinear_results_summary.csv'\n",
    "\n",
    "figures_folder = './figures'\n",
    "if not os.path.exists(figures_folder):\n",
    "    os.makedirs(figures_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c84698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process a single file\n",
    "def process_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filepath}: {e}\")\n",
    "            raise e\n",
    "    \n",
    "    # Extract columns, using placeholders for missing data\n",
    "    scenario_name = data.get(\"model_file\", \"-\").replace('.json', '')\n",
    "    algorithm = data.get(\"configuration\", {}).get(\"algorithm\", \"-\")\n",
    "    size = data.get(\"configuration\", {}).get(\"size\", \"-\")\n",
    "    optimizer = data.get(\"configuration\", {}).get(\"optimizer\", \"-\")\n",
    "    annealings = data.get(\"configuration\", {}).get(\"nonlinear_annealings\", \"-\")\n",
    "    iterations = data.get(\"configuration\", {}).get(\"nonlinear_iterations\", \"-\")\n",
    "\n",
    "    reasoner = data.get(\"reasoner_results\", {})\n",
    "    if isinstance(reasoner, str):\n",
    "        print(f\"File {filepath} has reasoner results as a string, converting to dict.\")\n",
    "        reasoner = {\"status\": reasoner}\n",
    "    status = reasoner.get(\"status\", \"-\")\n",
    "    score = reasoner.get(\"score\", \"-\")\n",
    "    evaluation = reasoner.get(\"evaluation\", \"-\")\n",
    "    exec_time = reasoner.get(\"solver_exec_time\", \"-\")\n",
    "    total_cost = reasoner.get(\"total_cost\", \"-\")\n",
    "    max_time = reasoner.get(\"max_time\", \"-\")\n",
    "    min_fidelity = reasoner.get(\"min_fidelity\", \"-\")\n",
    "    dispatch = reasoner.get(\"dispatch\", {})\n",
    "\n",
    "    if scenario_name == \"scenario2\":\n",
    "        evaluation = -evaluation\n",
    "\n",
    "    if  optimizer == \"nonlinear\":\n",
    "        baseline = \"qb-nonlinear\"\n",
    "    else:\n",
    "        raise ValueError(\"This function is for nonlinear optimizer results only.\")\n",
    "    # Row for DataFrame\n",
    "    row = {\n",
    "        #\"baseline\": baseline,\n",
    "        \"scenario_name\": scenario_name,\n",
    "        \"algorithm\": algorithm,\n",
    "        \"size\": size,\n",
    "        #\"optimizer\": optimizer,\n",
    "        \"annealings\": annealings,\n",
    "        \"iterations\": iterations,\n",
    "        \"status\": status,\n",
    "        #\"score\": score,\n",
    "        \"evaluation\": evaluation,\n",
    "        \"exec_time\": exec_time,\n",
    "        #\"total_cost\": total_cost,\n",
    "        #\"max_time\": max_time,\n",
    "        #\"min_fidelity\": min_fidelity\n",
    "    }\n",
    "    \n",
    "    # Key for dispatches dict\n",
    "    dispatch_key = (scenario_name, algorithm, size, optimizer, annealings, iterations)\n",
    "    \n",
    "    return row, dispatch_key, dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56745511",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 50 column 1 (char 1809)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m base_files = [os.path.join(folder_nonlinear, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(folder_nonlinear) \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m base_files:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     row, key, dispatch = \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     data_rows.append(row)\n\u001b[32m     11\u001b[39m     dispatches[key] = dispatch\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mprocess_file\u001b[39m\u001b[34m(filepath)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_file\u001b[39m(filepath):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Extract columns, using placeholders for missing data\u001b[39;00m\n\u001b[32m      7\u001b[39m     scenario_name = data.get(\u001b[33m\"\u001b[39m\u001b[33mmodel_file\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m).replace(\u001b[33m'\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:338\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    334\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    336\u001b[39m \n\u001b[32m    337\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m     end = _w(s, end).end()\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:354\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 50 column 1 (char 1809)"
     ]
    }
   ],
   "source": [
    "data_rows = []\n",
    "dispatches = {}\n",
    "\n",
    "if os.path.exists(csv_file_nonlinear):\n",
    "    df = pd.read_csv(csv_file_nonlinear)    \n",
    "else:\n",
    "    base_files = [os.path.join(folder_nonlinear, f) for f in os.listdir(folder_nonlinear) if f.endswith('.json')]\n",
    "    for file in base_files:\n",
    "        row, key, dispatch = process_file(file)\n",
    "        data_rows.append(row)\n",
    "        dispatches[key] = dispatch\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "    df.to_csv(csv_file_nonlinear, index=False)\n",
    "\n",
    "# Show results\n",
    "print(\"DataFrame:\")\n",
    "df['algorithm'] = df['algorithm'].replace('realamprandom', 'realamprnd')\n",
    "df['algorithm'] = df['algorithm'].replace('twolocalrandom', 'twolocalrnd')\n",
    "display(df)\n",
    "\n",
    "#print(\"\\nDispatches dictionary (keys and values):\")\n",
    "#for k, v in dispatches.items():\n",
    "#    print(f\"{k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832600bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b732a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by scenario_name, iterations, annealings and compute mean exec_time\n",
    "df_grouped = df.groupby(\n",
    "    ['scenario_name', 'iterations', 'annealings']\n",
    ")['exec_time'].mean().reset_index()\n",
    "\n",
    "df_grouped2 = df.groupby(\n",
    "    ['scenario_name', 'iterations', 'annealings']\n",
    ")['evaluation'].mean().reset_index()\n",
    "\n",
    "#fig, axes = plt.subplots(1, 2, figsize=(12, 12), sharey=True)\n",
    "\n",
    "\n",
    "for scenario in df_grouped['scenario_name'].unique():\n",
    "    plt.close('all')  # Ensure no leftovers\n",
    "    fig = plt.figure(figsize=(16, 7))\n",
    "    fig.suptitle(f\"Varying Nonlinear Solver Parameters: Scenario {scenario[-1]}\", fontsize=16)\n",
    "\n",
    "    # First plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    sub_df1 = df_grouped[df_grouped['scenario_name'] == scenario]\n",
    "    pivot1 = sub_df1.pivot_table(index='iterations', columns='annealings', values='exec_time')\n",
    "    X1, Y1 = np.meshgrid(pivot1.index, pivot1.columns)\n",
    "    Z1 = pivot1.values.T\n",
    "    surf1 = ax1.plot_surface(X1, Y1, Z1, cmap='viridis')\n",
    "    ax1.set_title('Solver Execution Time')\n",
    "    ax1.set_xlabel('Annealing Iterations')\n",
    "    ax1.set_ylabel('Annealings Runs')\n",
    "    ax1.set_zlabel('Average Execution Time')\n",
    "    fig.colorbar(surf1, ax=ax1, shrink=0.6, aspect=10, pad=0.1)\n",
    "\n",
    "    # Second plot\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    sub_df2 = df_grouped2[df_grouped2['scenario_name'] == scenario]\n",
    "    pivot2 = sub_df2.pivot_table(index='iterations', columns='annealings', values='evaluation')\n",
    "    X2, Y2 = np.meshgrid(pivot2.index, pivot2.columns)\n",
    "    Z2 = pivot2.values.T\n",
    "    surf2 = ax2.plot_surface(X2, Y2, Z2, cmap='viridis')\n",
    "    ax2.set_title('Objective Function Evaluation')\n",
    "    ax2.set_xlabel('Annealing Iterations')\n",
    "    ax2.set_ylabel('Annealings Runs')\n",
    "    ax2.set_zlabel('Average Evaluation')\n",
    "    fig.colorbar(surf2, ax=ax2, shrink=0.6, aspect=10, pad=0.1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.96, 0.95])\n",
    "    plt.savefig(f'{figures_folder}/{scenario}_nonlinear_analysis.pdf', format=\"pdf\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
